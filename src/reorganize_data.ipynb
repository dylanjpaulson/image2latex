{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total files: 103536\n",
      "First 5 files: ['100009e256.png', '10007a9101.png', '1000a29807.png', '1000f2a2d2.png', '10011a6bf8.png']\n",
      "Sorted files: ['100009e256.png', '10007a9101.png', '1000a29807.png', '1000f2a2d2.png', '10011a6bf8.png']\n"
     ]
    }
   ],
   "source": [
    "# Create an alphabetically sorted list of all the files in the directory\n",
    "\n",
    "import os\n",
    "\n",
    "# Get the list of all files and directories\n",
    "files = os.listdir('bin_formula_images')\n",
    "\n",
    "# Print the number of files\n",
    "print('Total files:', len(files))\n",
    "\n",
    "# Print the first 5 filenames\n",
    "print('First 5 files:', files[:5])\n",
    "\n",
    "# Sort the files\n",
    "files.sort()\n",
    "\n",
    "# Print the first 5 filenames\n",
    "print('Sorted files:', files[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of formulas: 103558\n",
      "Number of im2formula mappings: 9320\n"
     ]
    }
   ],
   "source": [
    "# Load the formula indices from the .lst file\n",
    "with open('data/im2latex_formulas_norm.lst', 'r', newline='\\n') as f:\n",
    "    formulas = []\n",
    "    for formula in f.readlines():\n",
    "        formulas.append(formula.strip())\n",
    "print('Number of formulas: {}'.format((len(formulas))-1))\n",
    "if len(formulas)-1 != 103558:\n",
    "    print('\\nError: Number of formulas does not match the number of formulas in the .lst file\\n')\n",
    "\n",
    "# Load the image-formula mapping from the .lst file\n",
    "im2formula = {}\n",
    "with open('data/im2latex_validate.lst', 'r') as f:\n",
    "    for line in f:\n",
    "        formula_idx, image_name, _ = line.strip().split()\n",
    "        im2formula[image_name + '.png'] = formulas[int(formula_idx)]\n",
    "print('Number of im2formula mappings: {}'.format(len(im2formula)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: \\int_{-\\epsilon}^\\infty dl\\: {\\rm e}^{-l\\zeta} \\int_{-\\epsilon}^\\infty dl' {\\rm e}^{-l'\\zeta} ll'{l'-l \\over l+l'} \\{3\\,\\delta''(l) - {3 \\over 4}t\\,\\delta(l) \\} =0. \\label{eq21}\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=1254x550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "\n",
    "labels = list(im2formula.keys())\n",
    "\n",
    "index = 0\n",
    "\n",
    "image_name = labels[index]\n",
    "\n",
    "# Load the image from a file path\n",
    "img_path = os.path.join('bin_formula_images', image_name)\n",
    "img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Convert the image to a PIL image\n",
    "img = Image.fromarray(img)\n",
    "\n",
    "label = im2formula[image_name]\n",
    "\n",
    "\n",
    "# Print the label\n",
    "print('Label: {}'.format(label))\n",
    "\n",
    "# Show the image in Jupyter notebook\n",
    "display(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 0 images\n",
      "Saved 1000 images\n",
      "Saved 2000 images\n",
      "Saved 3000 images\n",
      "Saved 4000 images\n",
      "Saved 5000 images\n",
      "Saved 6000 images\n",
      "Saved 7000 images\n",
      "Saved 8000 images\n",
      "Saved 9000 images\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "\n",
    "out_img_dir = 'processed_data/validate_images/'\n",
    "out_formula_file = 'processed_data/validate_formulas.txt'\n",
    "\n",
    "labels = list(im2formula.keys())\n",
    "\n",
    "formula_file = open(out_formula_file, 'w')\n",
    "\n",
    "for index in range(len(labels)):\n",
    "\n",
    "    image_name = labels[index]\n",
    "\n",
    "    # Load the image from a file path\n",
    "    img_path = os.path.join('bin_formula_images', image_name)\n",
    "    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    # Convert the image to a PIL image\n",
    "    img = Image.fromarray(img)\n",
    "\n",
    "    label = im2formula[image_name]\n",
    "\n",
    "    # Save the image\n",
    "    img.save(out_img_dir + image_name)\n",
    "\n",
    "    # Save the formula\n",
    "    string = image_name + ' ' + label + '\\n'\n",
    "\n",
    "    formula_file.write(string)\n",
    "\n",
    "    if index % 1000 == 0:\n",
    "        print('Saved {} images'.format(index))\n",
    "\n",
    "formula_file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files in processed_data/train_images: 83870\n",
      "Number of lines in processed_data/train_formulas.txt: 83870\n",
      "Number of files in processed_data/test_images: 10355\n",
      "Number of lines in processed_data/test_formulas.txt: 10355\n",
      "Number of files in processed_data/validate_images: 9320\n",
      "Number of lines in processed_data/validate_formulas.txt: 9320\n",
      "Number of files in processed_data/all_images: 103536\n",
      "Number of lines in processed_data/all_formulas.txt: 103536\n",
      "Sum of the number of files: 103545\n"
     ]
    }
   ],
   "source": [
    "# Print the number of files in processed_data/train_images\n",
    "print('Number of files in processed_data/train_images:', len(os.listdir('processed_data/train_images')))\n",
    "# Print the number of lines in processed_data/train_formulas.txt\n",
    "print('Number of lines in processed_data/train_formulas.txt:', len(open('processed_data/train_formulas.txt').readlines()))\n",
    "\n",
    "# Print the number of files in processed_data/test_images\n",
    "print('Number of files in processed_data/test_images:', len(os.listdir('processed_data/test_images')))\n",
    "# Print the number of lines in processed_data/test_formulas.txt\n",
    "print('Number of lines in processed_data/test_formulas.txt:', len(open('processed_data/test_formulas.txt').readlines()))\n",
    "\n",
    "# Print the number of files in processed_data/validate_images\n",
    "print('Number of files in processed_data/validate_images:', len(os.listdir('processed_data/validate_images')))\n",
    "# Print the number of lines in processed_data/validate_formulas.txt\n",
    "print('Number of lines in processed_data/validate_formulas.txt:', len(open('processed_data/validate_formulas.txt').readlines()))\n",
    "\n",
    "# Print the number of files in processed_data/all_images\n",
    "print('Number of files in processed_data/all_images:', len(os.listdir('processed_data/all_images')))\n",
    "# Print the number of lines in processed_data/formulas.txt\n",
    "print('Number of lines in processed_data/all_formulas.txt:', len(open('processed_data/all_formulas.txt').readlines()))\n",
    "\n",
    "\n",
    "# Print the sum of the number of files in processed_data/train_images, processed_data/test_images, and processed_data/validate_images\n",
    "print('Sum of the number of files:', len(os.listdir('processed_data/train_images')) + len(os.listdir('processed_data/test_images')) + len(os.listdir('processed_data/validate_images')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103545\n",
      "103536\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ['467a4dc80c.png', '10220a1920.png', '5f328ba860.png', '8237a4c556.png', '7c99ded238.png', '4ff536a32d.png', '662f0b83e3.png', '436abf1fe0.png', '50cd4d5615.png']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import re\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "\n",
    "class DataLoader(Dataset):\n",
    "    def __init__(self, image_directory, mapping_file, vocab_list, transform=None, tokens=50):\n",
    "        self.image_directory = image_directory\n",
    "        self.transform = transform\n",
    "        self.vocab_list = vocab_list\n",
    "        self.tokens = tokens\n",
    "\n",
    "        # Save the paths of the images\n",
    "        self.image_paths = []\n",
    "        for image_name in os.listdir(image_directory):\n",
    "            self.image_paths.append(os.path.join(image_directory, image_name))\n",
    "\n",
    "        # Load the image-formula mapping from the .lst file\n",
    "        self.im2formula = {}\n",
    "        with open(mapping_file, 'r') as f:\n",
    "            for line in f:\n",
    "                # Get the first item of the line\n",
    "                image_name = line.strip().split()[0]\n",
    "                # Get everything except the first item of the line, and join them together\n",
    "                formula = ' '.join(line.strip().split()[1:])\n",
    "\n",
    "        print('Number of images: {}'.format(len(self.image_paths)))\n",
    "        print('Number of im2formula mappings: {}'.format(len(self.im2formula)))\n",
    "\n",
    "    # Tokenize the formula\n",
    "    def split_string_by_tokens(string, vocab):\n",
    "        # Sort the vocabulary by length in descending order\n",
    "        vocab = sorted(vocab, key=len, reverse=True)\n",
    "\n",
    "        # Generate a regular expression pattern that matches any of the vocabulary words\n",
    "        pattern = \"|\".join(re.escape(word) for word in vocab)\n",
    "        \n",
    "        # Use the pattern to split the string into tokens\n",
    "        tokens = re.findall(pattern, string)\n",
    "        \n",
    "\n",
    "        # Add unknown tokens for any characters not matched by the pattern\n",
    "        str_index = 0\n",
    "        updated_tokens = []\n",
    "        i = 0\n",
    "        while i < (len(tokens)):\n",
    "            cur_token = tokens[i]\n",
    "            if string[str_index:str_index+len(cur_token)] == cur_token:\n",
    "                updated_tokens.append(cur_token)\n",
    "                str_index += len(cur_token)\n",
    "                i += 1\n",
    "            else:\n",
    "                updated_tokens.append(f\"<unk>\")\n",
    "                str_index += 1\n",
    "\n",
    "        if str_index != len(string):\n",
    "            for i in range(len(string) - str_index):\n",
    "                updated_tokens.append(f\"<unk>\") \n",
    "\n",
    "        return updated_tokens\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.im2formula)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        image_names = list(self.im2formula.keys())\n",
    "        image_name = image_names[index]\n",
    "\n",
    "        # Load the image from a file path\n",
    "        img = cv2.imread(self.image_paths[index], cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        # Convert the image to a PIL image\n",
    "        img = Image.fromarray(img)\n",
    "\n",
    "        formula = self.im2formula[image_name]\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        \n",
    "        # Tokenize the formula\n",
    "        tokenized_formula = DataLoader.split_string_by_tokens(formula, self.vocab_list)\n",
    "\n",
    "        if len(tokenized_formula) > self.tokens:\n",
    "            tokenized_formula = tokenized_formula[:self.tokens]\n",
    "        else:\n",
    "            for i in range(self.tokens - len(tokenized_formula)):\n",
    "                tokenized_formula.append('<pad>')\n",
    "        \n",
    "        # Insert <sos> token\n",
    "        tokenized_formula.insert(0, '<sos>')\n",
    "        # Append <eos> token\n",
    "        tokenized_formula.append('<eos>')\n",
    "\n",
    "        return img, tokenized_formula, image_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open vocab.txt and load each line into a list, remove new line character\n",
    "with open('data/vocab.txt', 'r') as f:\n",
    "    vocab_list = [line.strip() for line in f.readlines()]\n",
    "latex_vocab = Vocabulary(vocab_list)\n",
    "print('Vocab size: {}'.format(len(vocab_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = DataLoader('processed_data/all_images', 'processed_data/all_formulas.txt', latex_vocab.vocab_list, transform)\n",
    "data_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, shuffle=True, num_workers=8)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
